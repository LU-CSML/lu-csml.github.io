# CSML Talks Data
# Format:
#   - date: YYYY-MM-DD
#     speaker: Name
#     affiliation: University (optional)
#     title: Talk Title
#     links: URL (optional)
#     link_text: arXiv/NeurIPS/etc (optional)
# 2026


# Recommend Omar to LAI if no open slots
# Paula can take my date perhaps or ask .....

# Move Chris/Tiffany to 11th and confirm 

- date: 2026-06-25
  speaker: Chris Sherlock
  affiliation: Lancaster University
  title:
  abstract:

# Alexander could do 18th June
- date: 2026-06-18
  speaker: 
  affiliation:
  title:
  abstract:

- date: 2026-06-11
  speaker: Tiffany Vlaar
  affiliation: University of Glasgow
  title:
  abstract:
# Move Matti to 4th once Chris answers
- date: 2026-06-04
  speaker:
  affiliation: 
  title:
  abstract:

- date: 2026-05-28
  speaker: Edwin Fong
  affiliation: University of Hong Kong
  title: Quantile Martingale Posteriors
  abstract: "In this talk, we introduce a novel Bayesian nonparametric method for quantile estimation/regression based on the martingale posterior (MP) framework. The core idea of the MP is that posterior sampling is equivalent to predictive imputation, which allows us to break free of the stringent likelihood-prior specification. We demonstrate that a recursive estimate of a smooth quantile function, subject to a martingale condition, is entirely sufficient for full nonparametric Bayesian inference. We term the resulting posterior distribution as the quantile martingale posterior (QMP), which arises from an implicit generative predictive distribution. Associated with the QMP is an expedient, MCMC-free and parallelizable posterior computation scheme, which can be further accelerated with an asymptotic approximation based on a Gaussian process. Furthermore, the well-known issue of monotonicity in quantile estimation is naturally alleviated through increasing rearrangement due to the connections to the Bayesian bootstrap, and the QMP has a particularly tractable form that allows for comprehensive theoretical study."
  link: https://arxiv.org/abs/2406.03358
  link_text: arXiv

- date: 2026-05-21
  speaker: Gabriel Diaz-Aylwin
  affiliation: Lancaster University
  title:
  abstract:

- date: 2026-05-14
  speaker: Chris Nemeth
  affiliation: Lancaster University
  title:
  abstract:

- date: 2026-05-07
  speaker: Connie Trojan
  affiliation: Lancaster University
  title:
  abstract:

- date: 2026-04-30
  speaker: Masha Naslidnyk
  affiliation: University College London
  title: Kernel Quantile Embeddings and Associated Probability Metrics
  abstract: Embedding probability distributions into reproducing kernel Hilbert spaces (RKHS) has enabled powerful non-parametric methods such as the maximum mean discrepancy (MMD), a statistical distance with strong theoretical and computational properties. At its core, the MMD relies on kernel mean embeddings (KMEs) to represent distributions as mean functions in RKHS . However, it remains unclear if the mean function is the only meaningful RKHS representation. Inspired by generalised quantiles, we introduce the notion of kernel quantile embeddings (KQEs), along with a consistent estimator. We then use KQEs to construct a family of distances that (i) are probability metrics under weaker kernel conditions than MMD ;(ii) recover a kernelised form of the sliced Wasserstein distance; and(iii) can be efficiently estimated with near-linear cost. Through hypothesis testing, we show that these distances offer a competitive alternative to MMD and its fast approximations. Our findings demonstrate the value of representing distributions in Hilbert space beyond simple mean functions, paving the way for new avenues of research.
  link: https://arxiv.org/abs/2505.20433
  link_text: arXiv

- date: 2026-04-23
  speaker: Rui Zhang
  affiliation: Lancaster University
  title:
  abstract:

- date: 2026-03-19
  speaker: Liam Llamazares-Elias
  affiliation: Lancaster University
  title:
  abstract:

- date: 2026-03-12
  speaker: Chen Qi
  affiliation: Aalto University
  title:
  abstract:

- date: 2026-03-05
  speaker: Paul Fearnhead
  affiliation: Lancaster University
  title:
  abstract:

- date: 2026-02-26
  speaker: Jonas Latz
  affiliation: University of Manchester
  title: Sparse Techniques for Regression in Deep Gaussian Processes
  abstract: Gaussian processes (GPs) have gained popularity as flexible machine learning models for regression and function approximation with an in-built method for uncertainty quantification. GPs suffer when the amount of training data is large or when the underlying function contains multiscale features that are difficult to represent by an isotropic kernel. The training of GPs with large scale data is often performed through inducing point approximations (also known as sparse GP regression), where the size of the covariance matrices in GP regression is reduced considerably through a greedy search on the data set. Deep Gaussian processes have recently been introduced as hierarchical models that resolve multi-scale features by composing multiple Gaussian processes. Whilst GPs can be trained through a simple analytical formula, deep GPs require a sampling or, more usual, a variational approximation. Variational approximations lead to large-scale stochastic, non-convex optimisation problems and the resulting approximation tends to represent uncertainty incorrectly. In this work, we combine variational learning with MCMC to develop a particle-based expectation-maximisation method to simultaneously find inducing points within the large-scale data (variationally) and accurately train the Gaussian processes (sampling-based). The result is a highly efficient and accurate methodology for deep GP training on large scale data. We test the method on standard benchmark problems. Joint work with Aretha Teckentrup and Simon Urbainczyk.
  links:
    - url: https://iopscience.iop.org/article/10.1088/1361-6420/add9be
      text: Paper 1
    - url: https://arxiv.org/abs/2505.11355
      text: Paper 2

- date: 2026-02-19
  speaker: Matthias Sachs
  affiliation: Lancaster University
  title: 
  abstract: 
  slides:

- date: 2026-02-12
  speaker: Abiel Talwar 
  affiliation: Lancaster University
  title: 
  abstract: 
  slides:

- date: 2026-02-05
  speaker: Andre Menezes
  affiliation: Maynooth University
  title: Bayesian nonparametric models for zero-inflated count-compositional data using ensembles of regression trees.
  abstract: "Count-compositional data arise in many different fields, including high-throughput microbiome sequencing and palynology experiments, where a common, important goal is to understand how covariates relate to the observed compositions. Existing methods often fail to simultaneously address key challenges inherent in such data, namely: overdispersion, an excess of zeros, cross-sample heterogeneity, and nonlinear covariate effects. In this talk, we first present novel probabilistic portrayals of two multivariate models designed to handle zero-inflation in count-compositional data. Then, to address the above concerns, we propose novel Bayesian nonparametric models based on ensembles of regression trees. Specifically, we leverage the recently introduced zero-and-N-inflated multinomial distribution and assign independent nonparametric Bayesian additive regression tree (BART) priors to both the compositional and structural zero probability components of our model, to flexibly capture covariate effects. We further extend this by adding latent random effects to capture overdispersion and more general dependence structures among the categories. We develop an efficient inferential algorithm combining recent data augmentation schemes with established BART sampling routines. We evaluate our proposed models in simulation studies and illustrate their applicability with two case studies in microbiome and palaeoclimate modelling."
  slides:
  link: https://arxiv.org/abs/2601.08067
  link_text: arXiv

- date: 2026-01-29
  speaker: William Laplante
  affiliation: University College London
  title: Conjugate Generalised Bayesian Inference for Discrete Doubly Intractable Problems
  abstract: Doubly intractable problems occur when both the likelihood and the posterior are available only in unnormalised form, with computationally intractable normalisation constants. Bayesian inference then typically requires direct approximation of the posterior through specialised and typically expensive MCMC methods. In this paper, we provide a computationally efficient alternative in the form of a novel generalised Bayesian posterior that allows for conjugate inference within the class of exponential family models for discrete data. We derive theoretical guarantees to characterise the asymptotic behaviour of the generalised posterior, supporting its use for inference. The method is evaluated on a range of challenging intractable exponential family models, including the Conway-Maxwell-Poisson graphical model of multivariate count data, autoregressive discrete time series models, and Markov random fields such as the Ising and Potts models. The computational gains are significant; in our experiments, the method is between 10 and 6000 times faster than state-of-the-art Bayesian computational methods.
  link: https://arxiv.org/abs/2511.23275
  link_text: arXiv
  slides:
    

- date: 2026-01-22
  speaker: Yuga Iguchi
  affiliation: Lancaster University
  title: Dynamical regimes of denoising diffusion models for sampling from multimodal distributions
  abstract:  I will discuss the mechanism of denoising diffusion models (DDMs) for sampling from multimodal distributions on R^d. The first part of the talk will review the basics of DDMs — from discrete Markov chains to continuous-time formulations via SDEs. Then, using a mixture of two Gaussians as a canonical example of a multimodal target, I will describe how DDMs gradually transform the initial prior (a standard Gaussian) into the bimodal target distribution. In particular, I will show analytically that denoising trajectories dynamically change their behaviour during sampling, and that the denoising procedure can be characterised roughly by three stages: 1. Early stage — Contraction; 2. Intermediate stage — Expansion (contraction is lost); 3. Final stage — local attraction to a single mode, possibly contracting again locally. I will also clarify how these stages depend on properties of the target distribution, such as dimension, separation between modes, and the variances of the mixture components. This talk is based on ongoing joint work with Paul Fearnhead. 
  slides:

- date: 2026-01-15
  speaker: Hefin Lambley
  title: Autoencoders in function space
  affiliation: University of Warwick
  abstract: We propose function-space versions of autoencoders—machine-learning methods for dimension reduction and generative modelling—in both their deterministic (FAE) and variational (FVAE) forms. Formulating autoencoder objectives in function space enables training and evaluation with data discretised at arbitrary resolutions, leading to new applications such as inpainting, superresolution, and generative modelling. We discuss the technical challenges of formulating autoencoders in infinite dimension. A key issue is that FVAE's variational inference is often ill defined, unlike in finite dimensions, limiting its applicability. We then explore specific problem classes where FVAE remains useful. We contrast this with the FAE objective, which remains well defined in many situations where FVAE fails, making it a robust and versatile alternative. We demonstrate both methods on scientific data sets, including Navier--Stokes fluid flow simulations. This is joint work with Justin Bunker and Mark Girolami (Cambridge), Andrew M. Stuart (Caltech) and T. J. Sullivan (Warwick).
  link: https://arxiv.org/abs/2408.01362
  link_text: arXiv
  slides: pdf/2026-01-15.pdf
# 2025
- date: 2025-12-11
  speaker: Zheyang Shen
  affiliation: Newcastle University
  title: A Computable Measure of Suboptimality for Entropy-Regularised Variational Objectives
  slides: pdf/2025-12-11.pdf
  link: https://arxiv.org/abs/2509.10393
  link_text: arXiv
  abstract: "Several emerging post-Bayesian methods target a probability distribution for which an entropy-regularised variational objective is minimised. This increased flexibility introduces a computational challenge, as one loses access to an explicit unnormalised density for the target. To mitigate this difficulty, we introduce a novel measure of suboptimality called 'gradient discrepancy', and in particular a 'kernel' gradient discrepancy (KGD) that can be explicitly computed. In the standard Bayesian context, KGD coincides with the kernel Stein discrepancy (KSD), and we obtain a novel characterisation of KSD as measuring the size of a variational gradient. Outside this familiar setting, KGD enables novel sampling algorithms to be developed and compared, even when unnormalised densities cannot be obtained. To illustrate this point several novel algorithms are proposed and studied, including a natural generalisation of Stein variational gradient descent, with applications to mean-field neural networks and predictively oriented posteriors presented. On the theoretical side, our principal contribution is to establish sufficient conditions for desirable properties of KGD, such as continuity and convergence control."

- date: 2025-12-04
  speaker: Giorgos Vasdekis
  title: Sampling with time-changed Markov processes
  slides: /pdf/2025-12-04.pdf
  abstract: "We introduce a framework of time-changed Markov processes to speed up the convergence of Markov chain Monte Carlo (MCMC) algorithms in the context of multimodal distributions and rare event simulation. The time-changed process is defined by adjusting the speed of time of a base process via a user-chosen, state-dependent function. We apply this framework to several Markov processes from the MCMC literature, such as Langevin diffusions and piecewise deterministic Markov processes, obtaining novel modifications of classical algorithms and also re-discovering known MCMC algorithms. We prove theoretical properties of the time-changed process under suitable conditions on the base process, focusing on connecting the stationary distributions and qualitative convergence properties such as geometric and uniform ergodicity, as well as a functional central limit theorem. Time permitting, we will compare our approach with the framework of space transformations, clarifying the similarities between the approaches. This is joint work with Andrea Bertazzi."

- date: 2025-11-20
  speaker: Lanya Yang
  affiliation: Lancaster University
  title: Exchangeable Particle Gibbs for Markov Jump Processes
  abstract: "Inference in stochastic reaction-network models—such as the SEIR epidemic model or the Lotka–Volterra predator–prey system—is crucial for understanding the dynamics of interacting systems in epidemiology, ecology, and systems biology. These models are typically represented as Markov jump processes (MJPs) with intractable likelihoods. As a result, particle Markov chain Monte Carlo (particle MCMC) methods, particularly the Particle Gibbs (PG) sampler, have become standard tools for Bayesian inference. However, PG suffers from severe particle degeneracy, especially in high-dimensional state spaces, leading to poor mixing and inefficiency. In this talk, I focus on improving the efficiency of particle MCMC methods for inference in reaction networks by addressing the degeneracy problem. Building on recent work on the Exchangeable Particle Gibbs (xPG) sampler for continuous-state diffusions, this project develops a novel version of xPG tailored to discrete-state reaction networks, where randomness is driven by Poisson processes rather than Brownian motion. The proposed method retains the exchangeability framework of xPG while adapting it to the structural and computational challenges specific to reaction networks."
  slides: pdf/2025-11-20.pdf

- date: 2025-10-30
  speaker: Rui Zhang
  affiliation: Lancaster University
  title: A Dynamic Perspective of Matern Gaussian Processes
  abstract: The ubiquitous Gaussian process (GP) models in statistics and machine learning (Williams and Rasmussen; 2006) are static by default, either using the weight-space or function-space views (Kanagawa et al.; 2025), where the observation and test locations have no unilateral dependency order, and this also explains the cubic scalability in computational costs for GP regressions. On the other hand, the dynamic view of Gaussian processes, while only available for a class of GP models, reformulates the dependency structure unilaterally (Whittle; 1954) to enable sequential inferences for GP regressions with computational costs that could scale linearly (Hartikainen and Sarkka;2010; Sarkka and Hartikainen; 2012) with little to no approximation. This talk explores this dynamic perspective of (Matern) Gaussian processes and some consequences of this perspective.
  slides: pdf/2025-10-30.pdf
  links:
    - url: https://arxiv.org/pdf/2509.26005
      text: arXiv
    - url: pdf/2025-10-30-html/index.html
      text: HTML Slides

- date: 2025-10-16
  speaker: Henry Moss
  affiliation: Lancaster University
  title: "GPGreen: Linear Operator Learning with Gaussian Processes"

- date: 2025-09-04
  speaker: Rafael Izbicki
  affiliation: Federal University of São Carlos, Brazil
  title: Simulation‑Based Calibration of Confidence Sets for Statistical Models
  link: https://arxiv.org/abs/2508.17077
  link_text: arXiv

- date: 2025-08-07
  speaker: Jixiang Qing
  affiliation: Imperial College London
  title: Bayesian Optimization Over Graphs With Shortest-Path Encodings
  link: https://arxiv.org/abs/2503.05642
  link_text: arXiv

- date: 2025-07-17
  speaker: Maciej Buze
  title: Barycenters in Unbalanced Optimal Transport
  link: https://arxiv.org/abs/2305.02410
  link_text: arXiv

- date: 2025-07-03
  speaker: Henry Moss
  title: Fusing Neural and Statistical Models

- date: 2025-06-19
  speaker: Takuo Matsubara
  affiliation: University of Edinburgh
  title: "Wasserstein Gradient Boosting: A Framework for Distribution-Valued Supervised Learning"
  link: https://openreview.net/forum?id=cuO0DenqMl
  link_text: NeurIPS

- date: 2025-06-12
  speaker: Augustin Chevallier
  affiliation: University of Strasbourg
  title: "Towards Practical PDMP Sampling: Metropolis Adjustments, Locally Adaptive Step-Sizes, and NUTS-Based Time Lengths"
  link: https://arxiv.org/abs/2503.11479
  link_text: arXiv

- date: 2025-05-29
  speaker: Dennis Prangle
  affiliation: University of Bristol
  title: Distilling Importance Sampling for Likelihood Free Inference
  link: https://www.tandfonline.com/doi/full/10.1080/10618600.2023.2175688
  link_text: JCGS

- date: 2025-05-15
  speaker: Yuga Iguchi
  title: A Closed-Form Transition Density Expansion for Elliptic and Hypo-Elliptic SDEs
  link: https://www.arxiv.org/abs/2502.07047
  link_text: arXiv

- date: 2025-05-07
  speaker: Liam Llamazares Elias
  title: A Parameterization of Anisotropic Gaussian Fields With Penalized Complexity Priors
  link: https://arxiv.org/abs/2409.02331
  link_text: arXiv

- date: 2025-03-20
  speaker: Chris Nemeth
  title: Can ODEs Make Monte Carlo Methods Great Again?

- date: 2025-03-06
  speaker: Richard Everitt
  affiliation: University of Warwick
  title: ABC-SMC^2 and Ensemble Kalman Inversion ABC
  link: https://arxiv.org/abs/2407.18721
  link_text: arXiv

- date: 2025-02-20
  speaker: Paul Fearnhead
  title: Optimised Annealed Sequential Monte Carlo Samplers
  link: https://arxiv.org/abs/2408.12057
  link_text: arXiv

- date: 2025-02-06
  speaker: Adrien Corenflos
  affiliation: University of Warwick
  title: High-Dimensional Inference in State-Space Models via an Auxiliary Variable Trick
  link: https://arxiv.org/abs/2401.14868
  link_text: arXiv

- date: 2025-01-30
  speaker: Tim Rogers
  affiliation: University of Sheffield
  title: Learning About Dynamical Systems with Gaussian Processes

# 2024
- date: 2024-12-10
  speaker: Lorenzo Rimella
  affiliation: University of Turin
  title: Categorical Approximate Likelihood for individual-based models
  link: https://arxiv.org/abs/2501.03950
  link_text: arXiv

- date: 2024-11-28
  speaker: Connie Trojan
  title: Diffusion Generative Modelling for Divide-and-Conquer MCMC
  link: https://arxiv.org/abs/2406.11664
  link_text: arXiv

- date: 2024-11-21
  speaker: Maximillian Steffen
  affiliation: Karlsruhe Institute of Technology
  title: Statistical guarantees for stochastic Metropolis-Hastings
  link: https://arxiv.org/abs/2310.09335
  link_text: arXiv

- date: 2024-06-27
  speaker: Chris Sherlock
  title: "Tuning pseudo-marginal Metropolis-Hastings: a vase or two faces?"

- date: 2024-06-20
  speaker: Claire Gormley
  affiliation: University College Dublin
  title: Bayesian nonparametric modelling of network data
  arxiv: https://arxiv.org/pdf/2211.13034

- date: 2024-06-13
  speaker: Saifuddin Syed
  affiliation: University of Oxford
  title: Scaling inference of MCMC algorithms with parallel computing
  link: https://academic.oup.com/jrsssb/article/84/2/321/7056147
  link_text: JRSSB

- date: 2024-06-06
  speaker: Rui Zhang
  title: Unadjusted Barker as an SDE Numerical Scheme
  arxiv: https://arxiv.org/pdf/2405.14373

- date: 2024-05-16
  speaker: Wentao Li
  title: Optimal combination of composite likelihoods using approximate Bayesian computation with application to state-space models
  arxiv: https://arxiv.org/pdf/2404.02313

- date: 2024-05-09
  speaker: Gabriel Wallin
  title: Rotation to Sparse Loadings using Lp Losses and Related Inference Problems
  arxiv: https://arxiv.org/pdf/2206.02263

- date: 2024-04-11
  speaker: François-Xavier Briol
  title: Robust and conjugate Gaussian process regression
  arxiv: https://arxiv.org/pdf/2311.00463.pdf

- date: 2024-03-21
  speaker: Leandro Marcolino
  title: Identifying Adversaries in Ad-hoc Domains Using Q-valued Bayesian Estimations
  link: https://yelkhatib.github.io/papers/Alves2024amongus.pdf
  link_text: AAMAS

- date: 2024-03-14
  speaker: Theo Papamarkou
  title: Aspects of sampling-based inference for Bayesian neural networks

- date: 2024-03-07
  speaker: Tamas Papp
  title: Simulating the independence sampler parallel-in-time

- date: 2024-02-22
  speaker: Francesco Barile
  title: "Flexible modeling of heterogeneous populations of networks: a Bayesian nonparametric approach"

- date: 2024-02-15
  speaker: Kamélia Daudel
  title: "Alpha-divergence Variational Inference Meets Importance Weighted Auto-Encoders: Methodology and Asymptotics"
  link: https://www.jmlr.org/papers/volume24/22-1160/22-1160.pdf
  link_text: JMLR

- date: 2024-02-08
  speaker: Estevão Prado
  title: Accounting for shared covariates in semi-parametric Bayesian additive regression trees
  arxiv: https://arxiv.org/pdf/2108.07636.pdf

- date: 2024-02-01
  speaker: Lorenzo Rimella
  title: A State-Space Perspective on Modelling and Inference for Online Skill Rating
  arxiv: https://arxiv.org/pdf/2308.02414.pdf

# 2023
- date: 2023-12-14
  speaker: Chris Jewell
  title: Data Augmentation MCMC on epidemic models

- date: 2023-12-07
  speaker: Marina Riabiz
  title: Optimal Thinning of MCMC Output
  link: https://academic.oup.com/jrsssb/article/84/4/1059/7073269
  link_text: JRSSB

- date: 2023-11-30
  speaker: Lorenzo Rimella
  title: Simulation Based Composite Likelihood
  arxiv: https://arxiv.org/pdf/2310.10761.pdf

- date: 2023-11-23
  speaker: Andy Wang
  title: Comparison theorems for Hybrid Slice Sampling

- date: 2023-11-16
  speaker: Chris Sherlock
  title: Ensemble Kalman filter

- date: 2023-11-09
  speaker: Chris Nemeth
  title: Bayesian Flow Networks
  arxiv: https://arxiv.org/pdf/2308.07037.pdf

- date: 2023-11-02
  speaker: Aretha Teckentrup
  title: Gaussian processes, inverse problems and Markov chain Monte Carlo

- date: 2023-10-26
  speaker: Sam Holdstock
  title: Improved inference for stochastic kinetic models with small observation error via partial Rao-Blackwellisation

- date: 2023-10-19
  speaker: Estevão Prado
  title: Metropolis-Hastings with fast, flexible sub-sampling

- date: 2023-10-12
  speaker: Alberto Cabezas
  title: Composable Inference in BlackJAX

- date: 2023-06-29
  speaker: Tamas Papp
  title: Introduction to diffusion generative models

- date: 2023-06-22
  speaker: Chris Sherlock
  title: Fast return-level estimates for flood insurance via an improved Bennett inequality for random variables with differing upper bounds
  link: https://chrisgsherlock.github.io
  link_text: Ongoing work

- date: 2023-06-15
  speaker: Alice Corbella
  affiliation: University of Warwick
  title: The Lifebelt Particle Filter for robust estimation from low-valued count data
  arxiv: https://arxiv.org/pdf/2212.04400.pdf

- date: 2023-06-08
  speaker: Francesca Panero
  affiliation: London School of Economics
  title: Modelling sparse networks with Bayesian nonparametrics
  link: https://francescapanero.github.io/
  link_text: Ongoing work

- date: 2023-05-18
  speaker: Lorenzo Rimella
  title: "Localised filtering algorithm: the BPF and the Graph Filter"
  links:
    -url: https://arxiv.org/pdf/1301.6585.pdf
    text: arXiv
    -url: https://www.jmlr.org/papers/volume23/19-267/19-267.pdf
    text: JMLR

- date: 2023-05-11
  speaker: Francesca Crucinio
  affiliation: ENSAE
  title: Divide-and-Conquer SMC with applications to high dimensional filtering
  link: https://www3.stat.sinica.edu.tw/ss_newpaper/SS-2022-0243_na.pdf
  link_text: Statistica Sinica

- date: 2023-04-27
  speaker: Paul Fearnhead
  title: Automatic Differentiation of Programs with Discrete Randomness
  link: https://proceedings.neurips.cc/paper_files/paper/2022/hash/43d8e5fc816c692f342493331d5e98fc-Abstract-Conference.html
  link_text: NeurIPS

- date: 2023-03-02
  speaker: Chris Sherlock
  title: KSD for dummies

- date: 2023-02-23
  speaker: Victor Elvira
  affiliation: University of Edinburgh
  title: State-Space Models as Graphs
  arxiv: https://arxiv.org/pdf/2209.09969.pdf

- date: 2023-02-16
  speaker: Sam Livingstone
  affiliation: University College London
  title: Pre-conditioning in Markov chain Monte Carlo
  link: https://samueljlivingstone.wixsite.com/webpage
  link_text: Ongoing work

- date: 2023-01-26
  speaker: Estevao Batista Do Prado
  title: Bayesian additive regression trees (BART)
  links:
     -url: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1998.10473750
     text: JASA
     -url: https://projecteuclid.org/journals/annals-of-applied-statistics/volume-4/issue-1/BART-Bayesian-additive-regression-trees/10.1214/09-AOAS285.full
     text: Ann. Appl. Stat.

- date: 2023-01-19
  speaker: Alberto Cabezas Gonzalez
  title: Stereographic Markov Chain Monte Carlo
  arxiv: https://arxiv.org/pdf/2205.12112.pdf

- date: 2023-01-12
  speaker: Alexander Terenin
  affiliation: University of Cambridge
  title: Pathwise Conditioning and Non-Euclidean Gaussian Processes
  arxiv: https://arxiv.org/pdf/2202.10613.pdf

# 2022
- date: 2022-12-15
  speaker: Tamas Papp
  title: Coupling MCMC algorithms in high dimensions

- date: 2022-12-08
  speaker: Yu Luo
  title: Bayesian estimation using loss functions

- date: 2022-11-24
  speaker: Sam Power
  affiliation: University of Bristol
  title: "Explicit convergence bounds for Metropolis Markov chains: isoperimetry, spectral gaps and profiles"

- date: 2022-11-17
  speaker: Mauro Camara Escudero
  affiliation: University of Bristol
  title: Approximate Manifold Sampling

- date: 2022-11-03
  speaker: Alexandros Beskos
  affiliation: UCL
  title: Manifold Markov chain Monte Carlo methods for Bayesian inference in diffusion models

- date: 2022-10-27
  speaker: Jure Vogrinc
  affiliation: University of Warwick
  title: "The Barker proposal: Combining robustness and efficiency in gradient-based MCMC"

- date: 2022-10-20
  speaker: Paul Fearnhead
  title: Martingale posterior distributions

- date: 2022-10-06
  speaker: Michael Whitehouse
  affiliation: University of Bristol
  title: Consistent and fast inference in compartmental models of epidemics using PAL

- date: 2022-09-29
  speaker: Chris Sherlock
  title: Comparison of Markov chains via weak Poincaré inequalities with application to pseudo-marginal MCMC

- date: 2022-09-22
  speaker: Lorenzo Rimella
  title: Inference in Stochastic Epidemic Models via Multinomial Approximations

- date: 2022-09-15
  speaker: Chris Nemeth
  title: Metropolis–Hastings via Classification

- date: 2022-06-23
  speaker: Paul Fearnhead
  title: "Non-Reversible Parallel Tempering: a Scalable Highly Parallel MCMC Scheme"

- date: 2022-06-09
  speaker: Augustin Chevallier
  title: Continuously-Tempered PDMP samplers

- date: 2022-05-26
  speaker: Chris Sherlock
  title: Scalable Importance Tempering and Bayesian Variable Selection

- date: 2022-05-05
  speaker: Steffen Grünewälder
  title: Compressed Empirical Measures (in finite dimensions)

- date: 2022-03-31
  speaker: Louis Sharrock
  affiliation: University of Bristol
  title: Parameter Estimation for the McKean-Vlasov Stochastic Differential Equation

- date: 2022-03-24
  speaker: Alberto Cabezas Gonzalez
  title: Elliptical slice sampling

- date: 2022-03-17
  speaker: Augustin Chevallier
  title: Slice sampling & PDMP

- date: 2022-03-03
  speaker: Paul Fearnhead
  title: "Boost your favorite MCMC sampler using Kac’s theorem: the Kick-Kac teleportation algorithm- Part 2"

- date: 2022-02-24
  speaker: Paul Fearnhead
  title: "Boost your favorite MCMC sampler using Kac’s theorem: the Kick-Kac teleportation algorithm- Part 1"

- date: 2022-02-17
  speaker: Lionel Riou-Durand
  affiliation: University of Warwick
  title: "Metropolis Adjusted Underdamped Langevin Trajectories: a robust alternative to Hamiltonian Monte-Carlo"

- date: 2022-02-03
  speaker: Chris Sherlock
  title: Statistical scalability and approximate inference in distributed computing environments

- date: 2022-01-27
  speaker: Lorenzo Rimella
  title: "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables"

- date: 2022-01-20
  speaker: Augustin Chevallier
  title: Non-reversible guided Metropolis kernel

- date: 2022-01-13
  speaker: Szymon Urbas
  title: The Apogee to Apogee Path Sampler

# 2021
- date: 2021-12-09
  speaker: Chris Sherlock
  title: Metropolis-Hastings with Averaged Acceptance Ratios

- date: 2021-12-02
  speaker: Chris Nemeth
  title: Waste-free sequential Monte Carlo

- date: 2021-11-25
  speaker: Sam Power
  affiliation: University of Bristol
  title: Double Control Variates for Gradient Estimation in Discrete Latent Variable Models

- date: 2021-11-18
  speaker: Chris Nemeth
  title: How do you tune MCMC algorithms?

- date: 2021-11-04
  speaker: Augustin Chevallier
  title: Approximations of Piecewise Deterministic Markov Processes and their convergence properties

- date: 2021-10-28
  speaker: Paul Fearnhead
  title: Multilevel Linear Models, Gibbs Samplers and Multigrid Decompositions

- date: 2021-10-14
  speaker: Tamas Papp
  title: Estimating Markov chain convergence with empirical Wasserstein distance bounds

- date: 2021-06-22
  speaker: Gael Martin
  affiliation: Monash University
  title: "landmark papers: Bayesian computation from 1763 to the 21st Century"

- date: 2021-06-10
  speaker: Phyllis Ju
  affiliation: Harvard university
  title: Sequential Monte Carlo algorithms for agent-based models of disease transmission

- date: 2021-05-27
  speaker: Christian P. Robert
  affiliation: Université Paris-Dauphine
  title: "landmark papers: Harold Jeffreys’s Theory of Probability Revisited"

- date: 2021-05-13
  speaker: Lorenzo Rimella
  title: Dynamic Bayesian Neural Networks

- date: 2021-04-29
  speaker: Clement Lee
  title: "landmark papers: The Gelman-Rubin statistic: old and new"

- date: 2021-04-15
  speaker: George Bolt
  title: MCMC Sampling and Posterior Inference for a New Metric-Based Network Model

- date: 2021-03-25
  speaker: Jeremie Coullon
  title: "landmark papers: the Metropolis sampler (1953)"

- date: 2021-03-04
  speaker: Chris Sherlock
  title: Differentiable Particle Filtering via Entropy-Regularized Optimal Transport

# 2020
- date: 2020-11-19
  speaker: Liam Hodgkinson
  title: Stein kernels

- date: 2020-03-03
  speaker: Chris Nemeth
  title: "Deep generative modelling: autoencoders, VAEs, GANs…. and all that jazz! Part 2"

- date: 2020-02-27
  speaker: Chris Nemeth
  title: "Deep generative modelling: autoencoders, VAEs, GANs…. and all that jazz!"

- date: 2020-02-13
  speaker: Leah South
  title: The kernel Stein discrepancy

# 2019
- date: 2019-12-05
  speaker: Paul Fearnhead
  title: Zig Zag Sampler

- date: 2019-11-24
  speaker: Francois-Xavier Briol
  title: Statistical Inference for Generative Models with Maximum Mean Discrepancy
  abstract: "Likelihood-based inference and its variants provide a statistically efficient and widely applicable approach to parametric inference, their application to models involving intractable likelihoods poses challenges. In this work, we study a class of minimum distance estimators for intractable generative models, that is, statistical models for which the likelihood is intractable, but simulation is cheap. The distance considered, maximum mean discrepancy (MMD), is defined through the embedding of probability measures into a reproducing kernel Hilbert space."

- date: 2019-11-07
  speaker: Jeremias Knoblauch
  title: Generalized variational inference
  slides: /pdf/gvi_slides.pdf
  abstract: "In this talk, I introduce a generalized representation of Bayesian inference. It is derived axiomatically, recovering existing Bayesian methods as special cases. It is then used to prove that variational inference (VI) based on the Kullback-Leibler Divergence with a variational family Q produces the optimal Q-constrained approximation to the exact Bayesian inference problem. Surprisingly, this implies that standard VI dominates any other Q-constrained approximation to the exact Bayesian inference problem. This means that alternative Q-constrained approximations such as VI minimizing other divergences and Expectation Propagation can produce better posteriors than VI only by implicitly targeting more appropriate Bayesian inference problems."

- date: 2019-10-09
  speaker: Magnus Rattray
  title: Using Gaussian processes to infer pseudotime and branching from single-cell data.
  abstract: "I will describe some applications of Gaussian process models to single-cell data. We have developed a scalable implementation of the Gaussian process latent variable model (GPLVM) that can be used for pseudotime estimation when there is prior knowledge about pseudotime, e.g. from capture times available in single-cell time course data [1]. Other dimensions of the GPLVM latent space can then be used to model additional sources of variation, e.g. from branching of cells into different lineages."
- date: 2019-09-20
  speaker: Sam Livingstone
  title: On the robustness of gradient-based MCMC algorithms.
  abstract: "We analyse the tension between robustness and efficiency for Markov chain Monte Carlo (MCMC) sampling algorithms. In particular, we focus on robustness of MCMC algorithms with respect to heterogeneity in the target and their sensitivity to tuning, an issue of great practical relevance but still understudied theoretically. We show that the spectral gap of the Markov chains induced by classical gradient-based MCMC schemes (e.g. Langevin and Hamiltonian Monte Carlo) decays exponentially fast in the degree of mismatch between the scales of the proposal and target distributions, while for the random walk Metropolis (RWM) the decay is linear."

- date: 2019-08-01
  speaker: Leah South
  title: Variance reduction in MCMC.

- date: 2019-06-13
  speaker: Clement Lee
  title: Clustering approach and MCMC practicalities of stochastic block models.
  abstract: "Stochastic block model (SBM) is a popular choice for clustering nodes in a network. In this talk, a few versions of SBM will be reviewed, with the focus on the clustering approach (hard vs soft), and its relation with the subsequent MCMC algorithm. Model selection and some practical issues will also be discussed."

- date: 2019-05-09
  speaker: Nick Tawn
  title: The Annealed Leap Point Sampler (ALPS) for multimodal target distributions.
  abstract: "Sampling from multimodal target distributions is a classical challenging problem. Markov Chain Monte Carlo methods typically rely on localised or gradient based proposal mechanisms and so target distributions exhibiting multimodality mean the chain becomes trapped in a local mode and this results in a bias sample output. This talk introduces a novel algorithm, ALPS, that is designed to provide a scalable approach to sampling from multimodal target distributions. The ALPS algorithm concatenates a number of the strengths of the current gold standard approaches for multimodality."

- date: 2019-03-28
  speaker: Callum Vyner
  title: An Introduction to Divide-and-Conquer MCMC.

- date: 2019-02-28
  speaker: Matthew Ludkin
  title: "Hug ‘N’ Hop: Explicit, non-reversible, contour-hugging MCMC."

- date: 2019-02-14
  speaker: Henry Moss
  title: An Intro to Information-Driven Bayesian Optimisation

# 2018
- date: 2018-12-13
  speaker: Arnaud Doucet
  title: On discrete-time piecewise-deterministic MCMC schemes

- date: 2018-12-05
  speaker: Louis Aslett
  title: Privacy and Security in Bayesian Inference

- date: 2018-11-15
  speaker: Chris Sherlock
  title: The Minimal Extended Statespace Algorithm for exact inference on Markov jump processes

# 2017
- date: 2017-12-07
  speaker: Gareth Ridall
  title: Sequential Bayesian estimation and model selection
  abstract: "Work done in collaboration with Tony Pettitt from QUT Brisbane.I would like to: Introduce the Dirichlet form, which can be thought of as a generalisation of expected squared jumping distance, and show that the spectral gap has a variational representation over Dirichlet forms. Introduce the asymptotic variance of a Markov chain, which is the theoretical equivalent of the practical measure of 1/effective sample size, and provide a variational representation of this."

- date: 2017-11-29
  speaker: Chris Nemeth
  title: Pseudo-extended MCMC
  abstract: "MCMC algorithms are a class of exact methods used for sampling from target distributions. If the target is multimodal, MCMC algorithms often struggle to explore all of the modes of the target within a reasonable number of iterations. This issue can become even more pronounced when using efficient gradient-based samplers, such as HMC, which tend to tend to become trapped local modes. In this talk, I&rsquo;ll outline how the pseudo-extended target, based on pseudo-marginal MCMC, can be used to improve the mixing of the HMC sampler by tempering the target distribution."

- date: 2017-11-09
  speaker: Luke Kelly
  title: Lateral trait transfer in phylogenetic inference
  abstract: We are interested in inferring the phylogeny, or shared ancestry, of a set of species descended from a common ancestor. When traits pass vertically through ancestral relationships, the phylogeny is a tree and one can often compute the likelihood efficiently through recursions. Lateral transfer, whereby evolving species exchange traits outside of ancestral relationships, is a frequent source of model misspecification in phylogenetic inference. We propose a novel model of species diversification which explicitly controls for the effect of lateral transfer.

- date: 2017-11-01
  speaker: Yee Whye Teh
  title: On Bayesian Deep Learning and Deep Bayesian Learning
  abstract: Probabilistic and Bayesian reasoning is one of the principle theoretical pillars to our understanding of machine learning. Over the last two decades, it has inspired a whole range of successful machine learning methods and influenced the thinking of many researchers in the community. On the other hand, in the last few years the rise of deep learning has completely transformed the field and led to a string of phenomenal, era-defining, successes.

- date: 2017-05-18
  speaker: Chris Sherlock
  title: "Asymptotic variance and geometric convergence of MCMC: variational representations"
  abstract: An MCMC algorithm is geometrically ergodic if it converges to the intended posterior geometrically in the number of iterations. A number of useful properties follow from geometric ergodicity, including that the practical efficiency measure of &ldquo;effective sample size&rdquo; is meaningful for any sensible function of interest. The standard method for proving geometric ergodicity for a particular algorithm involves a &ldquo;drift condition&rdquo; and a &ldquo;small set&rdquo;, and can be time consuming, both in the proof itself and in understanding why the drift condition and small set are helpful.

- date: 2017-01-26
  speaker: Chris Sherlock
  title: "Delayed-acceptance MCMC with examples: advantages and pitfalls and how to avoid the latter"
  abstract: When conducting MCMC using the Metropolis-Hastings algorithm the posterior distribution must be evaluated at the proposed point at every iteration; in many situations, however, the posterior is computationally expensive to evaluate. When a computationally cheap approximation to the posterior is also available, the delayed acceptance algorithm (aka surrogate transition method) can be used to increase the efficiency of the MCMC whilst still targeting the correct posterior. In the first part of this talk I will explain and justify the algorithm itself and overview a number of examples of its (successful) application.

# 2016
- date: 2016-12-06
  speaker: Jack Baker
  title: An overview of Bayesian non-parametrics

- date: 2016-11-11
  speaker: Wentao Li
  title: Improved Convergence of Regression Adjusted Approximate Bayesian Computation

- date: 2016-10-20
  speaker: Paul Fearnhead
  title: "The Scalable Langevin Exact Algorithm: Bayesian Inference for Big Data"

- date: 2016-07-02
  speaker: Adam Johansen
  title: The iterated auxiliary particle filter

- date: 2016-05-19
  speaker: Chris Sherlock
  title: Pseudo-marginal MCMC using averages of unbiased estimators

- date: 2016-05-09
  speaker: Joris Bierkens
  affiliation: University of Warwick
  title: Super-efficient sampling using Zig Zag Monte Carlo

- date: 2016-04-14
  speaker: Paul Fearnhead
  title: Research opportunities with MCMC and Big Data

- date: 2016-03-17
  speaker: Peter Neal
  title: Optimal scaling of the independence sampler

- date: 2016-02-25
  speaker: Paul Fearnhead
  title: Continuous-Time Importance Sampling (and MCMC)

- date: 2016-02-18
  speaker: Borja de Balle Pigem
  title: Differentially Private Policy Evaluation

# 2015
- date: 2015-12-10
  speaker: Jack Baker
  title: STAN

- date: 2015-11-26
  speaker: Paul Fearnhead
  title: "Discussion of “The Bouncy Particle Sampler: A Non-Reversible Rejection-Free Markov Chain Monte Carlo Method”"
  links:
    -url: http://arxiv.org/pdf/1509.03808.pdf
    text: arXiv
    -url: http://arxiv.org/abs/1510.02451
    text: arXiv

- date: 2015-10-15
  speaker: James Hensman
  title: Variational inference in Gaussian process models

- date: 2015-05-19
  speaker: Alexandre Thiery
  affiliation: National University of Singapore
  title: Asymptotic Analysis of Random-Walk Metropolis on Ridged Densities

- date: 2015-04-28
  speaker: Chris Sherlock
  title: Delayed acceptance particle marginal random walk Metropolis algorithms and their optimisation

- date: 2015-03-05
  speaker: Chris Nemeth
  title: "Bayesian Inference for Big Data: Current and Future Directions"

# 2014
- date: 2014-12-18
  speaker: Wentao Li
  title: "Discussion of the RSS read paper: “Sequential Quasi Monte Carlo” by Mathieu Gerber and Nicolas Chopin."

- date: 2014-11-28
  speaker: Chris Nemeth
  title: Particle Metropolis adjusted Langevin algorithms

- date: 2014-03-11
  speaker: Paul Fearnhead
  title: Reparameterisations for Particle MCMC

- date: 2014-02-25
  speaker: Vasileios Maroulas
  affiliation: University of Tennessee
  title: Filtering, drift homotopy and target tracking

# 2013
- date: 2013-12-11
  speaker: Dennis Prangle
  affiliation: University of Bristol
  title: Speeding ABC inference using early-stopping simulations

- date: 2013-05-09
  speaker: Chris Sherlock
  title: Properties and Optimisation of the Pseudo Marginal RWM.

- date: 2013-04-17
  speaker: Anthony Lee
  affiliation: University of Warwick
  title: "Particle Markov chain Monte Carlo and marginal likelihood estimation: strategies for improvement."

- date: 2013-03-22
  speaker: Dennis Prangle
  title: Likelihood-free parameter estimation for state space models

- date: 2013-02-20
  speaker: Joe Mellor
  affiliation: University of Manchester
  title: Thompson Sampling in Switching Environments with Bayesian Online Change Point Detection

# 2012
- date: 2012-06-21
  speaker: Nicos Pavlidis
  affiliation: Lancaster University
  title: Classification in Dynamic Streaming Environments

- date: 2012-06-06
  speaker: Paul Fearnhead
  title: "Hamiltonian Monte Carlo: Beyond Kinetic Energy"

- date: 2012-05-22
  speaker: Chris Sherlock
  title: "Metropolis Adjusted Langevin Algorithm (MALA), simplified Manifold MALA, and Hamiltonian Monte Carlo: motivation, explanation and application"

- date: 2012-02-14
  speaker: Dennis Prangle
  title: Summary statistics for ABC model choice

# 2011
- date: 2011-12-13
  speaker: Paul Fearnhead
  title: "Constructing summary statistics for approximate Bayesian computation: semi-automatic ABC"
  link: http://arxiv.org/abs/1004.1112
  link_text: arXiv

- date: 2011-11-16
  speaker: Haeran Cho
  affiliation: London School of Economics
  title: High-dimensional variable selection via tilting

- date: 2011-06-17
  speaker: Gareth Ridall
  title: Online inference and model selection using sequential Monte Carlo

- date: 2011-05-24
  speaker: Chris Sherlock
  title: Simulation of mixed speed biochemical reactions using the linear noise approximation

- date: 2011-03-15
  speaker: Paul Fearnhead
  title: "Reading group on “An explicit link between Gaussian fields and Gaussian Markov random fields: The SPDE approach”"
  link: https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2011.00777.x
  link_text: RSS

- date: 2011-02-15
  speaker: Neil Drummond
  affiliation: Lancaster University
  title: Quantum Monte Carlo

- date: 2011-01-18
  speaker: Rebecca Killick
  title: Optimal detection of changepoints with a linear computational cost

# 2010
- date: 2010-12-07
  speaker: Dennis Prangle
  title: Using ABC for sequential Bayesian analysis

- date: 2010-11-10
  speaker: Krzysztof Latuszynski
  affiliation: University of Warwick
  title: Exact Inference for a Markov switching diffusion model with discretely observed data

- date: 2010-11-03
  speaker: Anastasia Lykou
  title: Bayesian variable selection using Lasso

- date: 2010-10-10
  speaker: Paul Fearnhead
  title: Reading group on “Riemann manifold Langevin and Hamiltonian Monte Carlo methods”
  link: http://arxiv.org/abs/0907.1100
  link_text: arXiv

- date: 2010-09-03
  speaker: Paul Fearnhead
  title: Particle Filters for models with fixed parameters

- date: 2010-02-16
  speaker: Gareth Ridall
  title: Reading group on Particle MCMC and the pseudo marginal algorithm

# 2009
- date: 2009-12-01
  speaker: Chris Sherlock
  title: "The random walk Metropolis: general criteria for the 0.234 acceptance rate rule"

- date: 2009-11-03
  speaker: Giorgos Sermaidis
  title: Likelihood based inference for discretely observed diffusions

- date: 2009-10-20
  speaker: Paul Fearnhead
  title: Sequential Importance Sampling for General Diffusion Models

- date: 2009-04-28
  speaker: Chris Sherlock
  affiliation: Reading Group
  title: The Integrated Nested Laplace Approximation of Rue et al. (2009)
  link: https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2008.00700.x
  link_text: RSS

# 2008
- date: 2008-12-02
  speaker: Paul Fearnhead
  title: change point models and fault detection

- date: 2008-10-28
  speaker: Chris Sherlock
  title: Optimal scaling of the random walk Metropolis - Part 1

- date: 2008-06-02
  speaker: Ben Taylor
  title: Adaptive Sequential Monte Carlo Methods For Static Inference in Bayesian Mixture Analysis

- date: 2008-05-13
  speaker: Joe Whittaker
  title: The linear least squares prediction view of conjugate gradients

- date: 2008-03-18
  speaker: Hongsheng Dai
  title: Perfect sampling for Random Trees

- date: 2008-03-04
  speaker: Dennis Prangle
  title: An MCMC method for Approximate Bayesian Computation

- date: 2008-02-05
  speaker: Paul Smith
  title: Bayesian Analysis of ARMA and Transfer Function Time Series Models

# 2007
- date: 2007-11-28
  speaker: Chris Sherlock
  title: Power sums of lognormals

- date: 2007-11-21
  speaker: Thomas Jaki
  title: Asymptotic simultaneous bootstrap confidence bounds for simple linear regression lines

- date: 2007-10-31
  speaker: Paul Fearnhead
  title: Using particle filters within MCMC